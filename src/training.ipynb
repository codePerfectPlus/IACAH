{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1faa7475",
   "metadata": {
    "id": "1faa7475"
   },
   "source": [
    "# IACAH (India Academia Connect AI Hackathon)\n",
    "\n",
    "Date - October 4-13, 2021\n",
    "\n",
    "Artificial intelligence will be an enormous part of the future workforce. Itâ€™s expected to generate 2 million net job gains versus losses by 2025. India Academia Connect AI Hackathon will help the participants from leading research institutions with the opportunity to learn and implement the latest AI technology, preparing them for a future AI-powered economy, with a large research and developer base.\n",
    "\n",
    "Data Download Link:- [GDrive Link](https://drive.google.com/drive/folders/1O8TT0s4zMyiI6zR-biVRoiLiAUy-W1H0?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83c2bf",
   "metadata": {
    "id": "ea83c2bf"
   },
   "source": [
    "#### Primary Goal:- To classify the Images into Background and Text\n",
    "    To Classify the Images into two categories(Background or Text) using Tensorflow and Keras.\n",
    "\n",
    "#### Solution:- \n",
    "    It's a Binary Class classification problem. It can be solved using CNN classifier.\n",
    "    Train the Model using transfer learning. We used VGG16 as feature extractor and used Dropout to avoid overfitting. we used some ImageDataAugmentation technique to make model more robust and better. we are using modelcheckpoint and earlystopping callbacks function to get the best model possible\n",
    "\n",
    "#### Result:- \n",
    "    we evalute the model on test_data(unseen data) using evlaute function and got the approx 92% accuracy. The Accuracy may be improve using new model like Resnet or Imagenet. Although Vgg16 is also works as feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a53e261",
   "metadata": {
    "id": "4a53e261"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb143c3",
   "metadata": {
    "id": "9bb143c3"
   },
   "outputs": [],
   "source": [
    "train_dir = \"training\" \n",
    "test_dir = \"test\"\n",
    "batch_size = 128\n",
    "img_shape = (64, 64, 3)\n",
    "epochs=10\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "idx_to_name = os.listdir(train_dir)\n",
    "name_to_idx = dict([(v, k) for k, v in enumerate(idx_to_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9661b3c",
   "metadata": {
    "id": "b9661b3c"
   },
   "outputs": [],
   "source": [
    "def data_to_df(data_dir, subset=None, train_size=None):\n",
    "    ''' Creating DataFrame for loading Filename and Label\n",
    "    \n",
    "    Args:\n",
    "        Data_dir: \n",
    "            Data_dir Path\n",
    "        Subset: \n",
    "            - train- for spliting data in train and val\n",
    "    \n",
    "     '''\n",
    "    df = pd.DataFrame(columns=['filenames', 'labels'])\n",
    "\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    for dataset in os.listdir(data_dir):\n",
    "        img_list = os.listdir(os.path.join(data_dir, dataset))\n",
    "\n",
    "        label = name_to_idx[dataset]\n",
    "\n",
    "        for image in img_list:\n",
    "            filenames.append(os.path.join(data_dir, dataset, image))\n",
    "            labels.append(label)\n",
    "\n",
    "    df[\"filenames\"] = filenames\n",
    "    df[\"labels\"] = labels\n",
    "    \n",
    "    if subset == \"train\":\n",
    "        train_df, val_df = train_test_split(df, train_size=train_size, shuffle=True)    \n",
    "        return train_df, val_df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc896050",
   "metadata": {
    "id": "fc896050"
   },
   "outputs": [],
   "source": [
    "train_df, val_df = data_to_df(train_dir, subset=\"train\", train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "IUqdJ0g2ZXWH",
   "metadata": {
    "id": "IUqdJ0g2ZXWH"
   },
   "outputs": [],
   "source": [
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    ''' Custom DataGenerator to load img \n",
    "    \n",
    "    Arguments:\n",
    "        data_frame = pandas data frame in filenames and labels format\n",
    "        batch_size = divide data in batches\n",
    "        shuffle = shuffle data before loading\n",
    "        img_shape = image shape in (h, w, d) format\n",
    "        augmentation = data augmentation to make model rebust to overfitting\n",
    "    \n",
    "    Output:\n",
    "        Img: numpy array of image\n",
    "        label : output label for image\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data_frame, batch_size=10, img_shape=None, augmentation=True, num_classes=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.train_len = self.data_frame.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.num_classes = num_classes\n",
    "        print(f\"Found {self.data_frame.shape[0]} images belonging to {self.num_classes} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        self.data_frame = shuffle(self.data_frame)\n",
    "        return int(self.train_len/self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # fix on epoch end it's not working, adding shuffle in len for alternative\n",
    "        pass\n",
    "    \n",
    "    def __data_augmentation(self, img):\n",
    "        img = tf.keras.preprocessing.image.random_shift(img, 0.2, 0.3)\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        return img\n",
    "        \n",
    "    def __get_image(self, file_id):\n",
    "        img = np.asarray(Image.open(file_id))\n",
    "        img = np.resize(img, self.img_shape)\n",
    "        #img = self.__data_augmentation(img)\n",
    "        img = preprocess_input(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __get_label(self, label_id):\n",
    "        return label_id\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.data_frame[\"filenames\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.data_frame[\"labels\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        # read your data here using the batch lists, batch_x and batch_y\n",
    "        x = [self.__get_image(file_id) for file_id in batch_x] \n",
    "        y = [self.__get_label(label_id) for label_id in batch_y]\n",
    "\n",
    "        return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "HF5VwAekbHc_",
   "metadata": {
    "id": "HF5VwAekbHc_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4700 images belonging to 2 classes\n",
      "Found 1175 images belonging to 2 classes\n"
     ]
    }
   ],
   "source": [
    "train_data = CustomDataGenerator(train_df, batch_size=batch_size, img_shape=img_shape, num_classes=num_classes)\n",
    "val_data = CustomDataGenerator(val_df, batch_size=batch_size, img_shape=img_shape, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc075e73",
   "metadata": {
    "id": "bc075e73"
   },
   "outputs": [],
   "source": [
    "base_model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=img_shape)\n",
    "base_model.trainable= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a85fcaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildModel(tf.keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super(BuildModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.globalaveragepooling = layers.GlobalAveragePooling2D()\n",
    "        self.dense1 = layers.Dense(128, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(2)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.base_model(inputs)\n",
    "        x = self.globalaveragepooling(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "384d57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(base_model)\n",
    "model.build(input_shape=(None, 64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa042671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"build_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  258       \n",
      "=================================================================\n",
      "Total params: 14,780,610\n",
      "Trainable params: 14,780,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "911ecc97-0eac-422e-9868-cf729c1feffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=1e-5)\n",
    "loss_fn = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "train_acc_metrics = metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metrics = metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76ee57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"tmp/\"\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b90a64e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "b90a64e7",
    "outputId": "b62137d7-3d02-4578-c146-e30db6918b8d"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metrics.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f3f1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_acc_metrics.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad99e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/5\n",
      "Step: 0 - Training loss : 5.8564252853393555\n",
      "Seen so far: 128 samples\n",
      "Step: 20 - Training loss : 0.8685746788978577\n",
      "Seen so far: 2688 samples\n",
      "Training Accuracy: 0.6833767294883728\n",
      "Validation Accuracy: 0.8472222089767456\n",
      "Time Taken: 245.45094969999997 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch : 1/5\n",
      "Step: 0 - Training loss : 0.9697527885437012\n",
      "Seen so far: 128 samples\n",
      "Step: 20 - Training loss : 0.7508831024169922\n",
      "Seen so far: 2688 samples\n",
      "Training Accuracy: 0.7927517294883728\n",
      "Validation Accuracy: 0.8940972089767456\n",
      "Time Taken: 151.10745339999994 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch : 2/5\n",
      "Step: 0 - Training loss : 0.45608749985694885\n",
      "Seen so far: 128 samples\n",
      "Step: 20 - Training loss : 0.19516485929489136\n",
      "Seen so far: 2688 samples\n",
      "Training Accuracy: 0.87109375\n",
      "Validation Accuracy: 0.9244791865348816\n",
      "Time Taken: 148.28833480000003 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch : 3/5\n",
      "Step: 0 - Training loss : 0.23227263987064362\n",
      "Seen so far: 128 samples\n",
      "Step: 20 - Training loss : 0.258573055267334\n",
      "Seen so far: 2688 samples\n",
      "Training Accuracy: 0.9157986044883728\n",
      "Validation Accuracy: 0.9461805820465088\n",
      "Time Taken: 149.38835519999998 seconds\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch : 4/5\n",
      "Step: 0 - Training loss : 0.17251542210578918\n",
      "Seen so far: 128 samples\n",
      "Step: 20 - Training loss : 0.11736097931861877\n",
      "Seen so far: 2688 samples\n",
      "Training Accuracy: 0.9405381679534912\n",
      "Validation Accuracy: 0.9600694179534912\n",
      "Time Taken: 148.96089080000002 seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "import time\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch : {epoch}/{epochs}\")\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_data):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "        \n",
    "        if (step % 20) == 0: \n",
    "            print(f\"Step: {step} - Training loss : {loss_value}\")\n",
    "            print(f\"Seen so far: {(step + 1) * batch_size} samples\") \n",
    "\n",
    "    train_acc = train_acc_metrics.result()\n",
    "    print(f\"Training Accuracy: {float(train_acc)}\")\n",
    "    train_acc_metrics.reset_states()\n",
    "\n",
    "    for x_batch_val, y_batch_val in val_data:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "    \n",
    "    val_acc = val_acc_metrics.result()\n",
    "    print(f\"Validation Accuracy: {float(val_acc)}\")\n",
    "    val_acc_metrics.reset_states()\n",
    "    \n",
    "    total_time = time.perf_counter() - start_time\n",
    "    \n",
    "    print(f\"Time Taken: {total_time} seconds\")\n",
    "    checkpoint.save(checkpoint_dir)\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1dd83f5",
   "metadata": {
    "id": "d1dd83f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4700 images belonging to 2 classes\n"
     ]
    }
   ],
   "source": [
    "test_df = data_to_df(\"test2\")\n",
    "test_data = CustomDataGenerator(train_df, batch_size=64, img_shape=img_shape, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c79b4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbeb0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evalution(test_data):\n",
    "    \"\"\" function to test the loss and accuracy on validation data \"\"\"\n",
    "    for X_test, y_test in val_data:\n",
    "        y_pred = model(X_test, training=False)\n",
    "        val_acc_metrics.update_state(y_test, y_pred)\n",
    "        accuracy = val_acc_metrics.result()\n",
    "    \n",
    "    return float(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d6707cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9600694179534912"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evalution(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9967c246",
    "outputId": "9a2c71c5-8f58-4fc3-ac9c-8ea3d6414128"
   },
   "outputs": [],
   "source": [
    "# Creating Json File to submit the solution\n",
    "final_output = {}\n",
    "for folder in os.listdir(\"test2\"):\n",
    "    for image_name in os.listdir(os.path.join(\"test2\", folder)):\n",
    "        img_ = image.load_img(os.path.join(\"test2\", folder, image_name), \n",
    "                              target_size=(64, 64), color_mode=\"rgb\")\n",
    "        img_arr = image.img_to_array(img_)\n",
    "        img_arr = preprocess_input(img_arr)\n",
    "        img_batch = np.array([img_arr])\n",
    "        output = model.predict(img_batch)\n",
    "        result = np.argmax(output)\n",
    "        final_output[image_name] = result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014dd312",
   "metadata": {
    "id": "014dd312"
   },
   "outputs": [],
   "source": [
    "with open(\"result.json\", \"w\") as file:\n",
    "    json.dump(final_output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c298de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
